/*
 * Copyright (C) 2020 Southern Storm Software, Pty Ltd.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */

/**
\file performance_phase2.dox
\page performance_phase2 Phase 2 Performance Figures
\tableofcontents

\section perf_phase2_intro Introduction

NIST set a cut-off of 18 Septeber 2020 for status updates from
the Round 2 candidate submission teams.  Since that date, some newer
implementations have been contributed by others and written by myself.

This page compares the performance of the original
\ref performance_baseline "baseline versions" with the newer
submissions for "Phase 2" of the project.  The original
\ref performance "performance page" has been updated with the new figures.

For phase 2, I am focusing mainly on the 32-bit ARM Cortex M3
microprocessor in the Arduino Due device that I used for previous
testing.  ESP32 and AVR figures may be included if they provide
interesting results.

\section perf_phase2_ascon ASCON and GASCON

The \ref performance_baseline "baseline" versions of ASCON-128, ASCON-128a,
and ASCON-80pq for 32-bit platforms use the 32-bit bit-sliced representation.
Plaintext and associated data is converted into bit-sliced form prior to being
absorbed by the permutation.  Squeezed ciphertext and the tag are
converted from bit-sliced form to regular form on output.

The GASCON core function was part of the DryGASCON submission to Round 2.
It is identical to ASCON except that the inputs and outputs of the permutation
are already in 32-bit bit-sliced form.  If DryGASCON is admitted to Round 3,
then the authors have suggested including GASCON in Round 3 as well in their
<a href="https://csrc.nist.gov/CSRC/media/Projects/lightweight-cryptography/documents/round-2/status-update-sep2020/DryGASCON_20200917-status-update.pdf">status update</a>.

Sébastien Riou of the DryGASCON submission team contributed versions of
ASCON-128, ASCON-128a, and ASCON-80pq where the GASCON permutation was
directly substituted for ASCON.  This avoids the need to convert back and
forth between bit-sliced form and regular form.  After applying his patch
and adding a few tweaks of my own, replacing ASCON with GASCON provided
between 12% and 17% improvement in performance on ARM Cortex M3:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>GASCON-128a</td><td>Sébastien Riou</td><td>1.48</td><td>1.44</td><td>1.56</td><td>1.58</td><td>1.52</td></tr>
<tr><td>ASCON-128a</td><td>Baseline</td><td>1.29</td><td>1.26</td><td>1.33</td><td>1.32</td><td>1.30</td></tr>
<tr><td>GASCON-128</td><td>Sébastien Riou</td><td>1.10</td><td>1.10</td><td>1.41</td><td>1.39</td><td>1.25</td></tr>
<tr><td>GASCON-80pq</td><td>Sébastien Riou</td><td>1.09</td><td>1.10</td><td>1.37</td><td>1.39</td><td>1.24</td></tr>
<tr><td>ASCON-80pq</td><td>Baseline</td><td>0.99</td><td>1.02</td><td>1.22</td><td>1.23</td><td>1.12</td></tr>
<tr><td>ASCON-128</td><td>Baseline</td><td>0.99</td><td>1.02</td><td>1.22</td><td>1.23</td><td>1.11</td></tr>
</table>

AVR tells a slightly different story because the bit-sliced representation
doesn't help improve ASCON performance on AVR due to the lack of a barrel
shifter.  The two AVR versions are almost identical except for the diffusion
layer.

The diffusion layer of ASCON-AVR operates on 64-bit words whereas the
diffusion layer of GASCON-AVR operates on 32-bit words.  This can lead to
slightly more housekeeping for the 32-bit version to deal with two sets of
carry bits during rotations.  With some extra loop unrolling or clever
register management, it may be possible to improve this, but the same trick
would also make ASCON-AVR faster.

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>ASCON-128a</td><td>Baseline</td><td>2.79</td><td>2.57</td><td>4.10</td><td>3.91</td><td>3.02</td></tr>
<tr><td>GASCON-128a</td><td>Rhys Weatherley</td><td>2.68</td><td>2.51</td><td>3.88</td><td>3.74</td><td>2.92</td></tr>
<tr><td>ASCON-80pq</td><td>Baseline</td><td>2.05</td><td>1.95</td><td>3.65</td><td>3.52</td><td>2.36</td></tr>
<tr><td>ASCON-128</td><td>Baseline</td><td>2.05</td><td>1.95</td><td>3.65</td><td>3.50</td><td>2.36</td></tr>
<tr><td>GASCON-80pq</td><td>Rhys Weatherley</td><td>1.99</td><td>1.91</td><td>3.48</td><td>3.38</td><td>2.29</td></tr>
<tr><td>GASCON-128</td><td>Rhys Weatherley</td><td>1.98</td><td>1.90</td><td>3.48</td><td>3.37</td><td>2.28</td></tr>
</table>

I have recently created an assembly code version of 32-bit bit-sliced ASCON
for ARM Cortex M3 and similar microprocessors, which can be found within
"src/combined/internal-ascon-arm-cm3.S" in the source tree.
The assembly code was generated by the code under "src/genarm".
For fairness, I also converted GASCON:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>GASCON-128a</td><td>Rhys Weatherley</td><td>2.14</td><td>1.88</td><td>2.11</td><td>1.97</td><td>2.01</td></tr>
<tr><td>ASCON-128a</td><td>Rhys Weatherley</td><td>1.86</td><td>1.70</td><td>1.80</td><td>1.78</td><td>1.78</td></tr>
<tr><td>GASCON-128</td><td>Rhys Weatherley</td><td>1.67</td><td>1.54</td><td>2.03</td><td>1.88</td><td>1.77</td></tr>
<tr><td>GASCON-80pq</td><td>Rhys Weatherley</td><td>1.64</td><td>1.51</td><td>1.91</td><td>1.78</td><td>1.71</td></tr>
<tr><td>ASCON-128</td><td>Rhys Weatherley</td><td>1.54</td><td>1.44</td><td>1.78</td><td>1.68</td><td>1.61</td></tr>
<tr><td>ASCON-80pq</td><td>Rhys Weatherley</td><td>1.52</td><td>1.43</td><td>1.71</td><td>1.65</td><td>1.57</td></tr>
<tr><td>ASCON-128a</td><td>Baseline</td><td>1.29</td><td>1.26</td><td>1.33</td><td>1.32</td><td>1.30</td></tr>
<tr><td>ASCON-80pq</td><td>Baseline</td><td>0.99</td><td>1.02</td><td>1.22</td><td>1.23</td><td>1.12</td></tr>
<tr><td>ASCON-128</td><td>Baseline</td><td>0.99</td><td>1.02</td><td>1.22</td><td>1.23</td><td>1.11</td></tr>
</table>

\section perf_phase2_comet COMET

I implemented ARM Cortex M3 assembly versions of the CHAM-128, CHAM-64, and
SPECK-64 block ciphers to accelerate COMET:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>COMET-128_CHAM-128/128</td><td>Rhys Weatherley</td><td>1.57</td><td>1.56</td><td>2.91</td><td>2.69</td><td>2.05</td></tr>
<tr><td>COMET-64_SPECK-64/128</td><td>Rhys Weatherley</td><td>1.42</td><td>1.43</td><td>2.86</td><td>2.75</td><td>1.94</td></tr>
<tr><td>COMET-128_CHAM-128/128</td><td>Baseline</td><td>1.22</td><td>1.25</td><td>2.20</td><td>2.08</td><td>1.61</td></tr>
<tr><td>COMET-64_SPECK-64/128</td><td>Baseline</td><td>1.16</td><td>1.14</td><td>2.31</td><td>2.24</td><td>1.58</td></tr>
<tr><td>COMET-64_CHAM-64/128</td><td>Rhys Weatherley</td><td>0.70</td><td>0.75</td><td>1.35</td><td>1.37</td><td>0.97</td></tr>
<tr><td>COMET-64_CHAM-64/128</td><td>Baseline</td><td>0.40</td><td>0.43</td><td>0.79</td><td>0.81</td><td>0.57</td></tr>
</table>

Both CHAM-128 and SPECK-64 are fully unrolled and fit entirely within the
ARM's register set.  Memory loads and stores are only required during
function setup and cleanup.  CHAM-64 requires some local stack space to
hold part of the key schedule as there aren't enough registers.

\section perf_phase2_dryascon DryGASCON

Sébastien Riou of the DryGASCON submission team contributed ARM Cortex M*
assembly code versions of DryGASCON128 with key sizes 16, 32, and 56.
The baseline version only had key size 16 and was written in C.

His submission also aligns the "x" words so that the entire "x" array
fits within a single cache line in the CPU.  This allows him to do away
with my complex constant-time method for selecting an "x" word.

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>DryGASCON128k32</td><td>Sébastien Riou</td><td>0.59</td><td>0.62</td><td>1.05</td><td>1.04</td><td>0.79</td></tr>
<tr><td>DryGASCON128k56</td><td>Sébastien Riou</td><td>0.59</td><td>0.62</td><td>1.05</td><td>1.03</td><td>0.79</td></tr>
<tr><td>DryGASCON128k16</td><td>Sébastien Riou</td><td>0.59</td><td>0.62</td><td>1.03</td><td>1.02</td><td>0.78</td></tr>
<tr><td>DryGASCON128k16</td><td>Baseline</td><td>0.16</td><td>0.18</td><td>0.28</td><td>0.30</td><td>0.22</td></tr>
</table>

DryGASCON128-HASH shows a similar improvement:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>1024 bytes</td><td>128 bytes</td><td>16 bytes</td><td>Average</td></tr>
<tr><td>DryGASCON128-HASH</td><td>Sébastien Riou</td><td>0.29</td><td>0.29</td><td>0.88</td><td>0.48</td></tr>
<tr><td>DryGASCON128-HASH</td><td>Baseline</td><td>0.08</td><td>0.07</td><td>0.25</td><td>0.13</td></tr>
</table>

\section perf_phase2_gift128 GIFT-128

I implemented ARM Cortex M3 assembly versions of the GIFT-128 block cipher
to support accelerated versions of the  the ESTATE, GIFT-COFB, HYENA, and
SUNDAE-GIFT submissions to Round 2.  Versions were created for the "full",
"small", and "tiny" variants of GIFT-128.  The following figures are for
the full fixsliced variant:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>GIFT-COFB</td><td>Rhys Weatherley</td></td><td>1.01</td><td>1.01</td><td>1.16</td><td>1.15</td><td>1.08</td></tr>
<tr><td>GIFT-COFB</td><td>Baseline</td></td><td>1.02</td><td>1.01</td><td>1.09</td><td>1.09</td><td>1.05</td></tr>
<tr><td>HYENA<td>Rhys Weatherley</td></td><td>0.68</td><td>0.74</td><td>0.87</td><td>0.88</td><td>0.80</td></tr>
<tr><td>SUNDAE-GIFT-0<td>Rhys Weatherley</td><td>0.57</td><td>0.61</td><td>1.04</td><td>1.05</td><td>0.78</td></tr>
<tr><td>SUNDAE-GIFT-0<td>Baseline</td><td>0.58</td><td>0.62</td><td>1.01</td><td>1.02</td><td>0.77</td></tr>
<tr><td>HYENA<td>Baseline</td></td><td>0.62</td><td>0.65</td><td>0.81</td><td>0.84</td><td>0.73</td></tr>
<tr><td>ESTATE_TweGIFT-128<td>Rhys Weatherley</td><td>0.53</td><td>0.57</td><td>1.04</td><td>1.04</td><td>0.74</td></tr>
<tr><td>SUNDAE-GIFT-64</td><td>Rhys Weatherley</td><td>0.54</td><td>0.58</td><td>0.84</td><td>0.86</td><td>0.69</td></tr>
<tr><td>SUNDAE-GIFT-64</td><td>Baseline</td><td>0.55</td><td>0.59</td><td>0.82</td><td>0.84</td><td>0.69</td></tr>
<tr><td>SUNDAE-GIFT-96</td><td>Rhys Weatherley</td><td>0.54</td><td>0.58</td><td>0.83</td><td>0.85</td><td>0.69</td></tr>
<tr><td>SUNDAE-GIFT-96</td><td>Baseline</td><td>0.55</td><td>0.59</td><td>0.81</td><td>0.83</td><td>0.68</td></tr>
<tr><td>SUNDAE-GIFT-128</td><td>Rhys Weatherley</td><td>0.54</td><td>0.58</td><td>0.81</td><td>0.83</td><td>0.68</td></tr>
<tr><td>SUNDAE-GIFT-128</td><td>Baseline</td><td>0.54</td><td>0.59</td><td>0.79</td><td>0.82</td><td>0.67</td></tr>
<tr><td>ESTATE_TweGIFT-128<td>Baseline</td><td>0.48</td><td>0.51</td><td>0.92</td><td>0.92</td><td>0.66</td></tr>
</table>

The assembly versions provided a modest improvement in performance, but
it wasn't as substantial as for other submissions.  The C compiler actually
does a pretty good job on my GIFT-128 block cipher implementations in C.

Further improvements will be investigated later.  The GIFT authors' ARM
implementations have some other tricks that I haven't implemented yet,
such as deferring word rotations from one step to be performed during
the following step.

\section perf_phase2_gimli Gimli

I implemented ARM Cortex M3 assembly versions of the GIMLI-24 permutation.
The implementation is fully unrolled with the entire state held in
registers.  The GIMLI-24 AEAD mode shows a 30% improvement over the baseline:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>GIMLI-24</td><td>Rhys Weatherley</td><td>1.08</td><td>1.09</td><td>1.29</td><td>1.28</td><td>1.18</td></tr>
<tr><td>GIMLI-24</td><td>Baseline</td><td>0.84</td><td>0.85</td><td>0.97</td><td>0.98</td><td>0.91</td></tr>
</table>

Similar improvements were seen for GIMLI-24-HASH:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>1024 bytes</td><td>128 bytes</td><td>16 bytes</td><td>Average</td></tr>
<tr><td>GIMLI-24-HASH</td><td>Rhys Weatherley</td><td>0.54</td><td>0.47</td><td>0.86</td><td>0.62</td></tr>
<tr><td>GIMLI-24-HASH</td><td>Baseline</td><td>0.45</td><td>0.35</td><td>0.61</td><td>0.46</td></tr>
</table>

\section perf_phase2_isap ISAP

Using the ARM Cortex M3 assembly version of ASCON provides an improvement
to the performance of ISAP-A:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>ISAP-A-128A</td><td>Rhys Weatherley</td><td>0.24</td><td>0.26</td><td>0.13</td><td>0.14</td><td>0.18</td></tr>
<tr><td>ISAP-A-128A</td><td>Baseline</td><td>0.17</td><td>0.19</td><td>0.10</td><td>0.11</td><td>0.13</td></tr>
<tr><td>ISAP-A-128</td><td>Rhys Weatherley</td><td>0.08</td><td>0.08</td><td>0.03</td><td>0.04</td><td>0.05</td></tr>
<tr><td>ISAP-A-128</td><td>Baseline</td><td>0.05</td><td>0.05</td><td>0.02</td><td>0.02</td><td>0.03</td></tr>
</table>

\section perf_phase2_pyjamask Pyjamask

Unrolling the circulant matrix multiplication step of Pyjamask produces a
three-fold performance improvement in the C version of the algorithm:

<table>
<tr><td>Algorithm</td><td>Version</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>Pyjamask-96-AEAD</td><td>Unrolled</td><td>0.22</td><td>0.25</td><td>0.25</td><td>0.27</td><td>0.25</td></tr>
<tr><td>Pyjamask-128-AEAD</td><td>Unrolled</td><td>0.22</td><td>0.24</td><td>0.24</td><td>0.25</td><td>0.24</td></tr>
<tr><td>Pyjamask-96-AEAD</td><td>Baseline</td><td>0.07</td><td>0.07</td><td>0.07</td><td>0.08</td><td>0.07</td></tr>
<tr><td>Pyjamask-128-AEAD</td><td>Baseline</td><td>0.06</td><td>0.07</td><td>0.07</td><td>0.07</td><td>0.07</td></tr>
</table>

Circulant multiplication has two arguments, a matrix "x" and a state
word "y", where the matrix is a constant.  The reference implementation
from the authors rotates and XOR's the matrix with the result wherever
there is a 1 bit in the state word:

\code
result ^= x & -((y >> bit) & 1);
x = rightRotate1(x);
\endcode

However, circulant multiplication is commutative so we can swap the
arguments.  Because the matrix is a constant, we only need to perform
XOR's and rotations for set bits in the matrix and ignore the unset bits.
The matrix values in the standard algorithm have an average of 12 set bits,
which reduces the number of XOR's and rotations significantly.  The
resulting implementation is approximately 10 times faster than the
baseline version:

<table>
<tr><td>Algorithm</td><td>Version</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>Pyjamask-96-AEAD</td><td>Reversed Multiplication</td><td>0.66</td><td>0.67</td><td>0.81</td><td>0.83</td><td>0.74</td></tr>
<tr><td>Pyjamask-128-AEAD</td><td>Reversed Multiplication</td><td>0.67</td><td>0.63</td><td>0.80</td><td>0.79</td><td>0.72</td></tr>
<tr><td>Pyjamask-96-AEAD</td><td>Baseline</td><td>0.07</td><td>0.07</td><td>0.07</td><td>0.08</td><td>0.07</td></tr>
<tr><td>Pyjamask-128-AEAD</td><td>Baseline</td><td>0.06</td><td>0.07</td><td>0.07</td><td>0.07</td><td>0.07</td></tr>
</table>

There is a caveat with swapping the arguments to circulant multiplication.
Pyjamask is strongly designed for resistance against power analysis.
It is unclear if doing the calculation in reverse order would alter the
power profile of the algorithm so as to make the state vulnerable.
For this reason I am still using the original argument order in the
masked version of Pyjamask.

I also experiemented with ARM Cortex M3 assembly versions of Pyjamask
but there wasn't much difference in performance to the plain C version.
So for now I am sticking with the C version with reversed arguments
as the primary implementation of unmasked Pyjamask.

\section perf_phase2_sparkle SPARKLE

I implemented fully unrolled ARM Cortex M3 assembly versions of the
SPARKLE-256, SPARKLE-384, and SPARKLE-512 permutations.  There was
up to a 70% improvement in performance in some of the algorithms.

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>Schwaemm128-128</td><td>Rhys Weatherley</td><td>1.60</td><td>1.58</td><td>2.84</td><td>2.39</td><td>2.01</td></tr>
<tr><td>Schwaemm256-128</td><td>Rhys Weatherley</td><td>1.74</td><td>1.63</td><td>1.90</td><td>1.93</td><td>1.80</td></tr>
<tr><td>Schwaemm192-192</td><td>Rhys Weatherley</td><td>1.47</td><td>1.50</td><td>1.98</td><td>1.81</td><td>1.68</td></tr>
<tr><td>Schwaemm128-128</td><td>Baseline</td><td>1.17</td><td>1.15</td><td>1.93</td><td>1.80</td><td>1.46</td></tr>
<tr><td>Schwaemm256-256</td><td>Rhys Weatherley</td><td>1.18</td><td>1.16</td><td>1.15</td><td>1.09</td><td>1.14</td></tr>
<tr><td>Schwaemm256-128</td><td>Baseline</td><td>1.08</td><td>1.12</td><td>1.08</td><td>1.10</td><td>1.09</td></tr>
<tr><td>Schwaemm192-192</td><td>Baseline</td><td>0.90</td><td>0.92</td><td>1.04</td><td>1.07</td><td>0.99</td></tr>
<tr><td>Schwaemm256-256</td><td>Baseline</td><td>0.79</td><td>0.80</td><td>0.74</td><td>0.72</td><td>0.76</td></tr>
</table>

The improvements to hashing performance was even more spectacular:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>1024 bytes</td><td>128 bytes</td><td>16 bytes</td><td>Average</td></tr>
<tr><td>Esch256</td><td>Rhys Weatherley</td><td>0.89</td><td>0.78</td><td>1.50</td><td>1.06</td></tr>
<tr><td>Esch384</td><td>Rhys Weatherley</td><td>0.45</td><td>0.37</td><td>1.50</td><td>0.47</td></tr>
<tr><td>Esch256</td><td>Baseline</td><td>0.38</td><td>0.34</td><td>0.65</td><td>0.46</td></tr>
<tr><td>Esch384</td><td>Baseline</td><td>0.26</td><td>0.21</td><td>0.33</td><td>0.26</td></tr>
</table>

The SPARKLE-256 and SPARKLE-384 implementations fit entirely within ARM
registers, with memory operations at the start and end of the permutation
functions only.  SPARKLE-512 holds 10 of the 16 state words in registers
at a time, and swaps the remaining the words between memory and registers
as needed in each round.

\section perf_phase2_tinyjambu TinyJAMBU

I replaced the common TinyJAMBU permutation function with three separate
unrolled versions for 128-bit, 192-bit, and 256-bit key sizes.  This
provided a modest improvement:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>TinyJAMBU-128</td><td>Rhys Weatherley</td><td>0.71</td><td>0.74</td><td>1.27</td><td>1.27</td><td>0.94</td></tr>
<tr><td>TinyJAMBU-192</td><td>Rhys Weatherley</td><td>0.63</td><td>0.67</td><td>1.14</td><td>1.16</td><td>0.85</td></tr>
<tr><td>TinyJAMBU-128</td><td>Baseline</td><td>0.59</td><td>0.62</td><td>1.10</td><td>1.11</td><td>0.81</td></tr>
<tr><td>TinyJAMBU-256</td><td>Rhys Weatherley</td><td>0.56</td><td>0.59</td><td>1.04</td><td>1.06</td><td>0.76</td></tr>
<tr><td>TinyJAMBU-192</td><td>Baseline</td><td>0.54</td><td>0.57</td><td>1.01</td><td>1.03</td><td>0.74</td></tr>
<tr><td>TinyJAMBU-256</td><td>Baseline</td><td>0.49</td><td>0.52</td><td>0.94</td><td>0.96</td><td>0.68</td></tr>
</table>

Improvements were also seen on ESP32 and AVR.

I then implemented an ARM Cortex M3 assembly code version of all three
permutations, which provides between 38% and 50% improvement over the
baseline versions:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>TinyJAMBU-128</td><td>Rhys Weatherley</td><td>0.93</td><td>0.95</td><td>1.63</td><td>1.61</td><td>1.21</td></tr>
<tr><td>TinyJAMBU-192</td><td>Rhys Weatherley</td><td>0.81</td><td>0.84</td><td>1.45</td><td>1.44</td><td>1.08</td></tr>
<tr><td>TinyJAMBU-256</td><td>Rhys Weatherley</td></td><td>0.70</td><td>0.73</td><td>1.28</td><td>1.29</td><td>0.94</td></tr>
<tr><td>TinyJAMBU-128</td><td>Baseline</td><td>0.59</td><td>0.62</td><td>1.10</td><td>1.11</td><td>0.81</td></tr>
<tr><td>TinyJAMBU-192</td><td>Baseline</td><td>0.54</td><td>0.57</td><td>1.01</td><td>1.03</td><td>0.74</td></tr>
<tr><td>TinyJAMBU-256</td><td>Baseline</td><td>0.49</td><td>0.52</td><td>0.94</td><td>0.96</td><td>0.68</td></tr>
</table>

The assembly versions of the TinyJAMBU-128 and TinyJAMBU-192 permutations
fit entirely within the ARM's register set.  The state words and key words
are loaded from memory into registers and kept there until the state words
are stored back to memory at the end of the permutation function.

TinyJAMBU-256 almost fits entirely within registers.  Three of the eight
key words need to be loaded from memory each round because there aren't
enough registers to keep the entire 256-bit key cached in registers.

The ARM assembly source code can be found in
"src/combined/internal-tinyjambu-arm-cm3.S" in the source tree.

\section perf_phase2_xoodyak Xoodyak

I implemented ARM Cortex M3 assembly versions of the Xoodoo permutation.
The implementation is fully unrolled with the entire state held in
registers.  The Xoodyak AEAD mode almost doubled in speed:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>Encrypt 128 bytes</td><td>Decrypt 128 bytes</td><td>Encrypt 16 bytes</td><td>Decrypt 16 bytes</td><td>Average</td></tr>
<tr><td>Xoodyak</td><td>Rhys Weatherley</td><td>1.66</td><td>1.51</td><td>1.73</td><td>1.60</td><td>1.62</td></tr>
<tr><td>Xoodyak</td><td>Baseline</td><td>0.85</td><td>0.87</td><td>0.84</td><td>0.85</td><td>0.86</td></tr>
</table>

Similar improvements were seen for the hashing mode:

<table>
<tr><td>Algorithm</td><td>Contributor</td><td>1024 bytes</td><td>128 bytes</td><td>16 bytes</td><td>Average</td></tr>
<tr><td>Xoodyak</td><td>Rhys Weatherley</td><td>0.71</td><td>0.65</td><td>1.43</td><td>0.93</td></tr>
<tr><td>Xoodyak</td><td>Baselin</td><td>0.38</td><td>0.35</td><td>0.79</td><td>0.51</td></tr>
</table>

*/
